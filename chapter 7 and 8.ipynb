{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2782b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Set your OpenAI API key as an environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# Access the API key from the environment variable\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Configure OpenAI with the API key\n",
    "openai.api_key = api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e8932e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.OpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "What is 2 raised to the 10th power?\u001b[32;1m\u001b[1;3m```text\n",
      "2**10\n",
      "```\n",
      "...numexpr.evaluate(\"2**10\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m1024\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: 1024'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, LLMMathChain\n",
    "llm = OpenAI(temperature=0)\n",
    "llm_math = LLMMathChain.from_llm(llm, verbose=True)\n",
    "llm_math.run(\"What is 2 raised to the 10th power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd06c023",
   "metadata": {},
   "outputs": [],
   "source": [
    " from langchain.agents import load_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a623dd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'C:\\\\Users\\\\DELL\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\langchain\\\\agents\\\\agent_toolkits' is not in the subpath of 'C:\\\\Users\\\\DELL\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\langchain_core' OR one path is relative and the other is absolute.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent_toolkits\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_python_agent\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PythonREPLTool\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\agents\\agent_toolkits\\__init__.py:78\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get attr name.\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_AGENTS:\n\u001b[1;32m---> 78\u001b[0m     relative_path \u001b[38;5;241m=\u001b[39m as_import_path(Path(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mparent, suffix\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m     79\u001b[0m     old_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m relative_path\n\u001b[0;32m     80\u001b[0m     new_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain_experimental.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m relative_path\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\path.py:30\u001b[0m, in \u001b[0;36mas_import_path\u001b[1;34m(file, suffix, relative_to)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     29\u001b[0m     file \u001b[38;5;241m=\u001b[39m Path(file)\n\u001b[1;32m---> 30\u001b[0m path \u001b[38;5;241m=\u001b[39m get_relative_path(file, relative_to\u001b[38;5;241m=\u001b[39mrelative_to)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[0;32m     32\u001b[0m     path \u001b[38;5;241m=\u001b[39m path[: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(file\u001b[38;5;241m.\u001b[39msuffix)]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\path.py:18\u001b[0m, in \u001b[0;36mget_relative_path\u001b[1;34m(file, relative_to)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     17\u001b[0m     file \u001b[38;5;241m=\u001b[39m Path(file)\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(file\u001b[38;5;241m.\u001b[39mrelative_to(relative_to))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\pathlib.py:730\u001b[0m, in \u001b[0;36mPurePath.relative_to\u001b[1;34m(self, *other)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (root \u001b[38;5;129;01mor\u001b[39;00m drv) \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m cf(abs_parts[:n]) \u001b[38;5;241m!=\u001b[39m cf(to_abs_parts):\n\u001b[0;32m    729\u001b[0m     formatted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_parsed_parts(to_drv, to_root, to_parts)\n\u001b[1;32m--> 730\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is not in the subpath of \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    731\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m OR one path is relative and the other is absolute.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    732\u001b[0m                      \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m), \u001b[38;5;28mstr\u001b[39m(formatted)))\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_parsed_parts(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, root \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    734\u001b[0m                                abs_parts[n:])\n",
      "\u001b[1;31mValueError\u001b[0m: 'C:\\\\Users\\\\DELL\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\langchain\\\\agents\\\\agent_toolkits' is not in the subpath of 'C:\\\\Users\\\\DELL\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\langchain_core' OR one path is relative and the other is absolute."
     ]
    }
   ],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents.agent_types import AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ce83e40",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_python_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m create_python_agent(\n\u001b[0;32m      2\u001b[0m  llm\u001b[38;5;241m=\u001b[39mOpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m),\n\u001b[0;32m      3\u001b[0m  tool\u001b[38;5;241m=\u001b[39mPythonREPLTool(),\n\u001b[0;32m      4\u001b[0m  verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m  agent_type\u001b[38;5;241m=\u001b[39mAgentType\u001b[38;5;241m.\u001b[39mZERO_SHOT_REACT_DESCRIPTION,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m agent_executor\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m      8\u001b[0m \u001b[38;5;250m \u001b[39m\u001b[38;5;124;03m\"\"\"Understand, write a single neuron neural network in PyTorch.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03mTake synthetic data for y=2x. Train for 1000 epochs and print every 100 \u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03mepochs.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mReturn prediction for x = 5\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_python_agent' is not defined"
     ]
    }
   ],
   "source": [
    "agent_executor = create_python_agent(\n",
    " llm=OpenAI(temperature=0, max_tokens=1000),\n",
    " tool=PythonREPLTool(),\n",
    " verbose=True,\n",
    " agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    ")\n",
    "agent_executor.run(\n",
    " \"\"\"Understand, write a single neuron neural network in PyTorch.\n",
    "Take synthetic data for y=2x. Train for 1000 epochs and print every 100 \n",
    "epochs.\n",
    "Return prediction for x = 5\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e5fb197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1930e091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.OpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for WolframAlphaAPIWrapper\n__root__\n  Did not find wolfram_alpha_appid, please add an environment variable `WOLFRAM_ALPHA_APPID` which contains it, or pass `wolfram_alpha_appid` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconversation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConversationBufferMemory\n\u001b[0;32m      2\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m tools \u001b[38;5;241m=\u001b[39m load_tools([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwolfram-alpha\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m memory \u001b[38;5;241m=\u001b[39m ConversationBufferMemory(memory_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m agent \u001b[38;5;241m=\u001b[39m initialize_agent(tools, llm, agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversational-react\u0002description\u001b[39m\u001b[38;5;124m\"\u001b[39m, memory\u001b[38;5;241m=\u001b[39mmemory, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\agents\\load_tools.py:613\u001b[0m, in \u001b[0;36mload_tools\u001b[1;34m(tool_names, llm, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    611\u001b[0m     _get_tool_func, extra_keys \u001b[38;5;241m=\u001b[39m _EXTRA_OPTIONAL_TOOLS[name]\n\u001b[0;32m    612\u001b[0m     sub_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m extra_keys \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs}\n\u001b[1;32m--> 613\u001b[0m     tool \u001b[38;5;241m=\u001b[39m _get_tool_func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msub_kwargs)\n\u001b[0;32m    614\u001b[0m     tools\u001b[38;5;241m.\u001b[39mappend(tool)\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\agents\\load_tools.py:230\u001b[0m, in \u001b[0;36m_get_wolfram_alpha\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_wolfram_alpha\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseTool:\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m WolframAlphaQueryRun(api_wrapper\u001b[38;5;241m=\u001b[39mWolframAlphaAPIWrapper(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for WolframAlphaAPIWrapper\n__root__\n  Did not find wolfram_alpha_appid, please add an environment variable `WOLFRAM_ALPHA_APPID` which contains it, or pass `wolfram_alpha_appid` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools(['wolfram-alpha'])\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "agent = initialize_agent(tools, llm, agent=\"conversational-react\u0002description\", memory=memory, verbose=True)\n",
    "agent.run(\n",
    " \"\"\"How far are these cities to Tokyo?\n",
    "* New York City\n",
    "* Madrid, Spain\n",
    "* Berlin\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6baa7ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "df = load_iris(as_frame=True)[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c36e6817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "from langchain import PromptTemplate\n",
    "from langchain.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0044f6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.OpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PROMPT = (\n",
    " \"If you do not know the answer, say you don't know.\\n\"\n",
    " \"Think step by step.\\n\"\n",
    " \"\\n\"\n",
    " \"Below is the query.\\n\"\n",
    " \"Query: {query}\\n\"\n",
    ")\n",
    "prompt = PromptTemplate(template=PROMPT, input_variables=[\"query\"])\n",
    "llm = OpenAI()\n",
    "agent = create_pandas_dataframe_agent(llm, df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36a71364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: This dataset contains data about flowers, specifically the sepal and petal measurements of different species of flowers.\n",
      "Action: python_repl_ast\n",
      "Action Input: df.describe()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count         150.000000        150.000000         150.000000   \n",
      "mean            5.843333          3.057333           3.758000   \n",
      "std             0.828066          0.435866           1.765298   \n",
      "min             4.300000          2.000000           1.000000   \n",
      "25%             5.100000          2.800000           1.600000   \n",
      "50%             5.800000          3.000000           4.350000   \n",
      "75%             6.400000          3.300000           5.100000   \n",
      "max             7.900000          4.400000           6.900000   \n",
      "\n",
      "       petal width (cm)  \n",
      "count        150.000000  \n",
      "mean           1.199333  \n",
      "std            0.762238  \n",
      "min            0.100000  \n",
      "25%            0.300000  \n",
      "50%            1.300000  \n",
      "75%            1.800000  \n",
      "max            2.500000  \u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This dataset contains numerical data for the sepal and petal measurements of different species of flowers.\n",
      "Action: python_repl_ast\n",
      "Action Input: df.info()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 4.8 KB\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This tells us that there are 150 entries in the dataset, all of which are numerical (float64) values.\n",
      "Action: python_repl_ast\n",
      "Action Input: df.shape\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m(150, 4)\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This tells us that there are 150 rows and 4 columns in the dataset.\n",
      "Action: python_repl_ast\n",
      "Action Input: df.columns\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIndex(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
      "       'petal width (cm)'],\n",
      "      dtype='object')\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This shows us the column names of the dataset.\n",
      "Final Answer: This dataset contains data about flowers, specifically the sepal and petal measurements of different species of flowers. It has 150 rows and 4 columns, all of which are numerical values. The column names are 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', and 'petal width (cm)'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"This dataset contains data about flowers, specifically the sepal and petal measurements of different species of flowers. It has 150 rows and 4 columns, all of which are numerical values. The column names are 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', and 'petal width (cm)'.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(prompt.format(query=\"What's this dataset about?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dad9ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To plot each column as a barplot, we need to use the matplotlib library.\n",
      "Action: import\n",
      "Action Input: matplotlib.pyplot as plt\u001b[0m\n",
      "Observation: import is not a valid tool, try one of [python_repl_ast].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use python_repl_ast to import matplotlib.pyplot as plt.\n",
      "Action: python_repl_ast\n",
      "Action Input: import matplotlib.pyplot as plt\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use python_repl_ast to plot each column as a barplot.\n",
      "Action: python_repl_ast\n",
      "Action Input: plt.bar(df.columns, df.iloc[0])\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m<BarContainer object of 4 artists>\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The barplot for each column is shown above.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The barplot for each column is shown above.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.run(prompt.format(query=\"Plot each column as a barplot!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12567f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: We need to use a statistical test to determine if two samples come from the same distribution.\n",
      "Action: [python_repl_ast]\n",
      "Action Input: import scipy.stats as stats\u001b[0m\n",
      "Observation: [python_repl_ast] is not a valid tool, try one of [python_repl_ast].\n",
      "Thought:\u001b[32;1m\u001b[1;3m We need to use a statistical test to determine if two samples come from the same distribution.\n",
      "Action: [python_repl_ast]\n",
      "Action Input: stats.ttest_ind(df['petal width (cm)'], df['petal length (cm)'])\u001b[0m\n",
      "Observation: [python_repl_ast] is not a valid tool, try one of [python_repl_ast].\n",
      "Thought:\u001b[32;1m\u001b[1;3m We need to use a statistical test to determine if two samples come from the same distribution.\n",
      "Action: [python_repl_ast]\n",
      "Action Input: stats.ttest_ind(df['petal width (cm)'], df['petal length (cm)'])\u001b[0m\n",
      "Observation: [python_repl_ast] is not a valid tool, try one of [python_repl_ast].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The t-test is not an appropriate statistical test to determine if two samples come from the same distribution. Instead, we should use a test such as the Kolmogorov-Smirnov test or the Anderson-Darling test.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The t-test is not an appropriate statistical test to determine if two samples come from the same distribution. Instead, we should use a test such as the Kolmogorov-Smirnov test or the Anderson-Darling test.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(prompt.format(query=\"Validate the following hypothesis statistically: petal width and petal length come from the same  distribution.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9094fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasai.llm import OpenAI\n",
    "from pandasai.schemas.df_config import Config\n",
    "from pandasai import SmartDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72f79f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 happiest countries are: Canada, Australia, United Kingdom, Germany, United States.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\"country\": [\"United States\", \"United Kingdom\", \"France\", \"Germany\", \n",
    "\"Italy\", \"Spain\", \"Canada\", \"Australia\", \"Japan\", \"China\"],\n",
    "                   \n",
    " \"gdp\": [19294482071552, 2891615567872, 2411255037952, 3435817336832, \n",
    "1745433788416, 1181205135360, 1607402389504, 1490967855104, 4380756541440, \n",
    "14631844184064],\n",
    " \"happiness_index\": [6.94, 7.16, 6.66, 7.07, 6.38, 6.4, 7.23, 7.22, 5.87, 5.12]})\n",
    "\n",
    "\n",
    "smart_df = SmartDataframe(df, config=Config(llm=OpenAI()))\n",
    "\n",
    "\n",
    "print(smart_df.chat(\"Which are the 5 happiest countries?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c07979f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skllm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpalm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PaLMClassifier\n\u001b[0;32m      2\u001b[0m clf \u001b[38;5;241m=\u001b[39m PaLMClassifier(n_update_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      3\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train) \u001b[38;5;66;03m# y_train is a list of labels\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skllm'"
     ]
    }
   ],
   "source": [
    "from skllm.models.palm import PaLMClassifier\n",
    "clf = PaLMClassifier(n_update_steps=100)\n",
    "clf.fit(X_train, y_train) # y_train is a list of labels\n",
    "labels = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b7ee5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement skllm (from versions: none)\n",
      "ERROR: No matching distribution found for skllm\n"
     ]
    }
   ],
   "source": [
    "pip install skllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c67b6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13830899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The sentiment of the text is negative.'\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI()\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=\"Classify the sentiment of this text: {text}\")\n",
    "chain = prompt | model\n",
    "\n",
    "print(chain.invoke({\"text\": \"I hated that movie, it was terrible!\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea8fb79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [{\n",
    "    \n",
    "\"input\": \"I absolutely love the new update! Everything works seamlessly.\",\n",
    " \"output\": \"Positive\",\n",
    " },{\n",
    " \"input\": \"It's okay, but I think it could use more features.\",\n",
    " \"output\": \"Neutral\",\n",
    " }, {\n",
    " \"input\": \"I'm disappointed with the service, I expected much better performance.\",\n",
    " \"output\": \"Negative\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92e979a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dddad96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Positive'\n"
     ]
    }
   ],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    \n",
    " template=\"{input} - {output}\",\n",
    " input_variables=[\"input\", \"output\"],)\n",
    "\n",
    "prompt = FewShotPromptTemplate( examples=examples, example_prompt=example_prompt,\n",
    " suffix=\"Question: {input}\",input_variables=[\"input\"])\n",
    "\n",
    "print((prompt | ChatOpenAI()).invoke({\"input\": \"\"\" This is an excellent book with high quality\n",
    "explanations.\"\"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1de00ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71d5b102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Step 1: Start with 5 apples.\\nStep 2: Eat 2 apples. \\nResult: 5 - 2 = 3 apples remaining.\\nStep 3: My friend gives me 3 apples. \\nResult: 3 + 3 = 6 apples now.\\nFinal answer: I have 6 apples now.'\n"
     ]
    }
   ],
   "source": [
    "reasoning_prompt = \"{question} \\n Let's think step by step!\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    " template=reasoning_prompt,\n",
    " input_variables=[\"question\"])\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "print(chain.invoke({\n",
    " \"question\": \"\"\"There were 5 apples originally. I ate 2 apples. My friend \n",
    "gave me 3 apples. How many apples do I have now?\"\"\",}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7b79324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "solutions_template = \"\"\"\n",
    "Generate {num_solutions} distinct answers to this question:\n",
    "{question}\n",
    "Solutions:\n",
    "\"\"\"\n",
    "solutions_prompt = PromptTemplate(\n",
    " template=solutions_template,\n",
    " input_variables=[\"question\", \"num_solutions\"]\n",
    ")\n",
    "solutions_chain = LLMChain(\n",
    " llm=ChatOpenAI(),\n",
    " prompt=solutions_prompt,\n",
    " output_key=\"solutions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76f995ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "consistency_template = \"\"\"\n",
    "For each answer in {solutions}, count the number of times it occurs. \n",
    "Finally, choose the answer that occurs most.\n",
    "Most frequent solution: \n",
    "\"\"\"\n",
    "consistency_prompt = PromptTemplate(\n",
    " template=consistency_template,\n",
    " input_variables=[\"solutions\"]\n",
    ")\n",
    "consistency_chain = LLMChain(\n",
    " llm=ChatOpenAI(),\n",
    " prompt=consistency_prompt,\n",
    " output_key=\"best_solution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b44aac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "answer_chain = SequentialChain(\n",
    " chains=[solutions_chain, consistency_chain],\n",
    "    \n",
    " input_variables=[\"question\", \"num_solutions\"],\n",
    " output_variables=[\"best_solution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9dfb81f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer that occurs most frequently is 1. The Declaration of Independence of the Republic of India was signed in 1947.\n"
     ]
    }
   ],
   "source": [
    "print(answer_chain.run(\n",
    " question=\"Which year was the Declaration of Independence of the Republic OF India signed?\",\n",
    " num_solutions=\"5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c51afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
